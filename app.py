# app.py â€” Ø¥ØµØ¯Ø§Ø± Ø°ÙƒÙŠ ÙŠØ·Ø§Ø¨Ù‚ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø¨Ø¯Ù‚Ø© ÙÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
from flask import Flask, request, jsonify
from sentence_transformers import SentenceTransformer
from sklearn.neighbors import NearestNeighbors
import google.generativeai as genai
from langdetect import detect
import json, os, re, requests

app = Flask(__name__)
genai.configure(api_key="AIzaSyBEeidGnK_uyf9ikJWW9elsAgDdz8t09oA")

FAQ_PATH = os.path.join(os.path.dirname(__file__), "faq.json")
embedder = SentenceTransformer("all-MiniLM-L6-v2")

TOP_K = 5
EMB_WEIGHT = 0.7
TOKEN_WEIGHT = 0.3
COMBINED_THRESHOLD = 0.60

ARABIC_STOPWORDS = {
    "ÙÙŠ","Ù…Ù†","Ù…Ø§","Ù‡ÙŠ","Ù…Ø§Ù‡ÙŠ","Ù…Ø§ Ù‡ÙŠ","Ù„Ù…","Ø¹Ù†","Ø¹Ù„Ù‰","Ùˆ","Ø§Ùˆ","Ø£Ùˆ",
    "Ù‡Ù„","ÙƒÙŠÙ","Ø£ÙŠÙ†","ÙƒÙ…","Ù‡Ø°Ø§","Ù‡Ø°Ù‡","Ø°Ù„Ùƒ","ØªÙƒÙˆÙ†","ÙŠÙƒÙˆÙ†","Ù‡Ùˆ","Ù‡ÙŠ","Ø¥Ù„Ù‰","Ø¨"
}

SERVICE_ENDPOINTS = {
    "resource_groups": "https://api.mueen.com.sa/ar/api/ResourceGroup/GetResourceGroupsByService?serviceId={serviceId}",
    "fixed_package": "https://api.mueen.com.sa/ar/api/HourlyContract/FixedPackage?stepId={stepId}&nationalityId={nationalityId}&shift={shift}"
}

questions, answers, token_sets = [], [], []
nn_model = NearestNeighbors(n_neighbors=1, metric="cosine")

# ==================== Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ====================
def normalize_ar(text):
    t = (text or "").lower()
    t = re.sub(r'[^\u0600-\u06FF0-9\s]', ' ', t)
    return re.sub(r'\s+', ' ', t).strip()

def tokens_from_text(text):
    return [w for w in normalize_ar(text).split() if w and w not in ARABIC_STOPWORDS]

def token_overlap_score(q_tokens, c_tokens):
    if not c_tokens:
        return 0.0
    return len(set(q_tokens) & set(c_tokens)) / max(len(c_tokens), 1)

def load_faq_data():
    if not os.path.exists(FAQ_PATH):
        return []
    with open(FAQ_PATH, "r", encoding="utf-8") as f:
        return json.load(f)

def build_index_from_memory():
    global nn_model
    if not questions:
        return
    embeddings = embedder.encode(questions, show_progress_bar=False)
    k = min(len(questions), TOP_K)
    nn_model = NearestNeighbors(n_neighbors=k, metric="cosine")
    nn_model.fit(embeddings)

def initialize_memory():
    global questions, answers, token_sets
    data = load_faq_data()
    questions[:] = [d["question"] for d in data]
    answers[:] = [d["answer"] for d in data]
    token_sets[:] = [tokens_from_text(q) for q in questions]
    if questions:
        build_index_from_memory()
        print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(questions)} Ø³Ø¤Ø§Ù„ ÙˆØ¨Ù†Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³.")

initialize_memory()

# ==================== ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ ====================
AR_NUM_WORDS = {
    "ÙˆØ§Ø­Ø¯Ø©": 1, "ÙˆØ§Ø­Ø¯": 1, "Ø§Ø«Ù†ÙŠÙ†": 2, "Ø«Ù†ØªÙŠÙ†": 2, "Ø«Ù„Ø§Ø«": 3, "Ø«Ù„Ø§Ø«Ø©": 3,
    "Ø£Ø±Ø¨Ø¹": 4, "Ø£Ø±Ø¨Ø¹Ø©": 4, "Ø§Ø±Ø¨Ø¹Ø©": 4, "Ø®Ù…Ø³Ø©": 5, "Ø³Øª": 6, "Ø³ØªØ©": 6,
    "Ø³Ø¨Ø¹": 7, "Ø³Ø¨Ø¹Ø©": 7, "Ø«Ù…Ø§Ù†": 8, "Ø«Ù…Ø§Ù†ÙŠØ©": 8, "ØªØ³Ø¹": 9, "Ø¹Ø´Ø±": 10, "Ø¹Ø´Ø±Ø©": 10
}

def extract_hours_from_text(text):
    if not text:
        return None
    text = text.lower()
    # Ø§Ø¨Ø­Ø« Ø¹Ù† Ø±Ù‚Ù… Ù…Ø¨Ø§Ø´Ø±
    num_match = re.search(r'(\d+)', text)
    if num_match:
        num = int(num_match.group(1))
        if 1 <= num <= 24:
            return num
    # Ø§Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø© Ø±Ù‚Ù…ÙŠØ© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    for word, val in AR_NUM_WORDS.items():
        if word in text:
            return val
    return None

# ==================== Ø§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª API ====================
def fetch_resource_groups(service_id):
    try:
        url = SERVICE_ENDPOINTS["resource_groups"].format(serviceId=service_id)
        r = requests.get(url, timeout=8)
        r.raise_for_status()
        return r.json().get("data", [])
    except Exception as e:
        print("fetch_resource_groups error:", e)
        return []

def fetch_fixed_package(stepId, nationalityId, shift=1):
    try:
        url = SERVICE_ENDPOINTS["fixed_package"].format(stepId=stepId, nationalityId=nationalityId, shift=shift)
        r = requests.get(url, timeout=8)
        r.raise_for_status()
        return r.json().get("data", {})
    except Exception as e:
        print("fetch_fixed_package error:", e)
        return {}

def find_service_by_keyword(text):
    mapping = {
        "ØªÙ†Ø¸ÙŠÙ": "1f9b952b-60dc-ee11-b772-000d3a236f24",
        "ØªÙ†Ø¸ÙŠÙ Ø¨Ù„Ø³": "9c273825-4fdd-ee11-b772-000d3a236f24",
        "Ø¶ÙŠØ§ÙØ©": "0ef5bce8-6257-f011-b78d-000d3a236f24",
        "Ø¬Ù„ÙŠØ³Ø©": "e0f43214-d583-ef11-b77b-000d3a236f24",
        "Ø·Ø¨Ø§Ø®Ø©": "da502fd9-a36a-ef11-b77a-000d3a236f24"
    }
    for kw, sid in mapping.items():
        if kw in text:
            return kw, sid
    return None, None

# ==================== Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø§Ù„Ø£Ø³Ø¹Ø§Ø± ====================
def get_dynamic_answer_for_price(text):
    text = text.lower()
    if not any(x in text for x in ["Ø³Ø¹Ø±", "ÙƒÙ…", "ØªÙƒÙ„ÙØ©", "price", "cost", "Ø¹Ø±Ø¶"]):
        return None

    kw, service_id = find_service_by_keyword(text)
    if not service_id:
        return None

    groups = fetch_resource_groups(service_id)
    if not groups:
        return None

    first_group = groups[0]
    nationalityId = first_group["key"]
    nationalityName = first_group["value"]

    step_id = "2006851d-e10e-4217-b7aa-919d20e08993"
    data = fetch_fixed_package(step_id, nationalityId, shift=1)
    pkgs = data.get("selectedPackages", [])
    if not pkgs:
        return None

    wanted_hours = extract_hours_from_text(text)
    chosen_pkg = None

    # Ø§Ø¨Ø­Ø« Ø¹Ù† Ø¨Ø§Ù‚Ø© Ø¨Ù†ÙØ³ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø£Ùˆ Ø§Ù„Ø£Ù‚Ø±Ø¨
    if wanted_hours:
        closest_diff = 999
        for pkg in pkgs:
            pkg_hours = int(pkg.get("visitHours") or pkg.get("hoursNumber") or 0)
            diff = abs(pkg_hours - wanted_hours)
            if diff < closest_diff:
                closest_diff = diff
                chosen_pkg = pkg
    else:
        chosen_pkg = pkgs[0]

    name = chosen_pkg.get("displayName", "")
    hours = chosen_pkg.get("visitHours") or chosen_pkg.get("hoursNumber")
    final_price = float(chosen_pkg.get("finalPrice") or 0)
    promo = chosen_pkg.get("promotionOfferList", [])
    promo_text = ""
    if promo:
        promo_text = " â€” " + "; ".join(p.get("promotionDescription", "") for p in promo)

    return f"Ù„Ø®Ø¯Ù…Ø© '{kw}' ({nationalityName}): {name} Ù„Ù…Ø¯Ø© {hours} Ø³Ø§Ø¹Ø§Øª Ø¨Ø³Ø¹Ø± {final_price:.2f} Ø±ÙŠØ§Ù„{promo_text}"

# ==================== FAQ ====================
def get_best_answer_from_faq(user_input):
    if not questions:
        return None
    user_vec = embedder.encode([user_input])
    dist, idxs = nn_model.kneighbors(user_vec, n_neighbors=min(TOP_K, len(questions)))
    best_idx = idxs[0][0]
    return answers[best_idx]

# ==================== ØªØ±Ø¬Ù…Ø© ====================
def translate_with_gemini(text, target_lang="Arabic"):
    try:
        model = genai.GenerativeModel("models/gemini-2.5-pro")
        resp = model.generate_content(f"Translate to {target_lang} only:\n{text}")
        return resp.text.strip()
    except Exception:
        return text

# ==================== CHAT ====================

@app.route("/chat", methods=["POST"])
def chat():
    body = request.json or {}
    user_input_raw = body.get("message", "")
    context = body.get("context", {}) or {}

    current_page = context.get("currentPage", "")
    visible_data = context.get("visibleData", {})

    # ğŸ”¥ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø­Ø«
    if current_page == "HourlyPackagesPage":
        service = visible_data.get("selectedService", "")
        packages = visible_data.get("availablePackages", [])
        offers = visible_data.get("offers", [])

        # Ù„Ùˆ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙÙŠÙ‡ ÙƒÙ„Ù…Ø© "Ø³Ø¹Ø±" Ø£Ùˆ "ØªÙƒÙ„ÙØ©" ÙˆØ§Ù„Ø¨ÙˆØª Ø¹Ø§Ø±Ù Ø§Ù„Ø¨Ø§Ù‚Ø§Øª Ù…Ù† Ø§Ù„ØµÙØ­Ø©:
        if any(word in user_input_raw for word in ["Ø³Ø¹Ø±", "ØªÙƒÙ„ÙØ©", "price", "cost"]):
            if packages:
                return jsonify({
                    "reply": f"Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù€ {service}ØŒ Ø§Ù„Ø¨Ø§Ù‚Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù‡ÙŠ: {', '.join(packages)}. "
                             f"Ø­Ø§Ù„ÙŠÙ‹Ø§ ÙŠÙˆØ¬Ø¯ {offers[0] if offers else 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ø±ÙˆØ¶ Ø­Ø§Ù„ÙŠØ§Ù‹'}."
                })

    # ğŸ” Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚ (Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù„ØºØ© + Ø§Ù„Ø¨Ø­Ø« ÙÙŠ FAQ + Ø§Ù„ØªØ±Ø¬Ù…Ø©)
    user_input = user_input_raw
    candidate_answer = get_best_answer_from_faq(user_input)

    if not candidate_answer:
        candidate_answer = "Ù„Ù… Ø£Ø¬Ø¯ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù†Ø§Ø³Ø¨Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„."

    return jsonify({"reply": candidate_answer})

if __name__ == "__main__":
    app.run(port=5000, debug=True)
